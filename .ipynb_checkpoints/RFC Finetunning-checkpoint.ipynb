{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ead7af-0b9c-448b-8b9e-68bc2320fada",
   "metadata": {},
   "source": [
    "## RandomForest Classifier Hyperparameter finetunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf8a16a7-2e5f-42f0-a585-6505c7ac8e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn, sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5dc74fe-0525-43ad-bce7-d4070ae5b87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes -> Train: (16800, 11) Val: (3600, 11) Test: (3600, 11)\n",
      "Train label distribution:\n",
      " label\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Val   label distribution:\n",
      " label\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Test  label distribution:\n",
      " label\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pairs_df = pd.read_csv(\"synth_pairs_large.csv\")\n",
    "\n",
    "# Create short text fields for each side\n",
    "def make_text_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"name_left\"]  = (df[\"first_name_left\"].astype(str)  + \" \" + df[\"last_name_left\"].astype(str))\n",
    "    df[\"name_right\"] = (df[\"first_name_right\"].astype(str) + \" \" + df[\"last_name_right\"].astype(str))\n",
    "    # Option A (no OHE): also feed country tokens into hashing\n",
    "    df[\"country_left_txt\"]  = df[\"country_left\"].astype(str)\n",
    "    df[\"country_right_txt\"] = df[\"country_right\"].astype(str)\n",
    "    return df\n",
    "\n",
    "pairs_df = make_text_cols(pairs_df)\n",
    "\n",
    "# 70/30 first\n",
    "train_df, temp_df = train_test_split(\n",
    "    pairs_df, test_size=0.30, stratify=pairs_df[\"label\"], random_state=SEED\n",
    ")\n",
    "# 15/15 from the remaining 30%\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.50, stratify=temp_df[\"label\"], random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"Split sizes -> Train:\", train_df.shape, \"Val:\", val_df.shape, \"Test:\", test_df.shape)\n",
    "print(\"Train label distribution:\\n\", train_df[\"label\"].value_counts(normalize=True).round(3))\n",
    "print(\"Val   label distribution:\\n\", val_df[\"label\"].value_counts(normalize=True).round(3))\n",
    "print(\"Test  label distribution:\\n\", test_df[\"label\"].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a94c6b-ec09-47eb-9572-705bc9c5a8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: shape=(16800, 5), nnz=58,687, density=0.698655\n",
      "X_val  : shape=(3600, 5), nnz=12,676, density=0.704222\n",
      "X_test : shape=(3600, 5), nnz=12,571, density=0.698389\n",
      "Targets -> y_train: (16800,) y_val: (3600,) y_test: (3600,)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Pairwise TF-IDF → cosine similarities (names + countries)\n",
    "text_cols = [\"name_left\", \"name_right\", \"country_left_txt\", \"country_right_txt\"]\n",
    "\n",
    "#  Fit TF-IDF encoders on TRAIN ONLY (concat left/right to build vocab) ---\n",
    "tfidf_name = TfidfVectorizer(analyzer=\"char\", ngram_range=(2,5), sublinear_tf=True, lowercase=False)\n",
    "tfidf_country = TfidfVectorizer(analyzer=\"char\", ngram_range=(2,5), sublinear_tf=True, lowercase=False)\n",
    "\n",
    "tfidf_name.fit(pd.concat([train_df[\"name_left\"], train_df[\"name_right\"]], axis=0))\n",
    "tfidf_country.fit(pd.concat([train_df[\"country_left_txt\"], train_df[\"country_right_txt\"]], axis=0))\n",
    "\n",
    "def _pairwise_features_to_sparse(df: pd.DataFrame) -> sparse.csr_matrix:\n",
    "    # Transform each side\n",
    "    nl = tfidf_name.transform(df[\"name_left\"])\n",
    "    nr = tfidf_name.transform(df[\"name_right\"])\n",
    "    cl = tfidf_country.transform(df[\"country_left_txt\"])\n",
    "    cr = tfidf_country.transform(df[\"country_right_txt\"])\n",
    "\n",
    "    # Cosine similarities (as dense 1-D arrays)\n",
    "    name_sim = cosine_similarity(nl, nr).diagonal()\n",
    "    country_sim = cosine_similarity(cl, cr).diagonal()\n",
    "\n",
    "    # Simple auxiliary signals\n",
    "    fn_len_diff = (df[\"first_name_left\"].astype(str).str.len() - df[\"first_name_right\"].astype(str).str.len()).abs().to_numpy()\n",
    "    ln_len_diff = (df[\"last_name_left\"].astype(str).str.len()  - df[\"last_name_right\"].astype(str).str.len()).abs().to_numpy()\n",
    "    country_eq  = (df[\"country_left_txt\"] == df[\"country_right_txt\"]).astype(int).to_numpy()\n",
    "\n",
    "    # Stack into a sparse CSR (5 feature columns)\n",
    "    M = np.column_stack([name_sim, country_sim, fn_len_diff, ln_len_diff, country_eq]).astype(float)\n",
    "    return sparse.csr_matrix(M)\n",
    "\n",
    "# Build split matrices\n",
    "X_train_sparse = _pairwise_features_to_sparse(train_df)\n",
    "X_val_sparse   = _pairwise_features_to_sparse(val_df)\n",
    "X_test_sparse  = _pairwise_features_to_sparse(test_df)\n",
    "\n",
    "# Targets (unchanged)\n",
    "y_train = train_df[\"label\"].astype(int).to_numpy()\n",
    "y_val   = val_df[\"label\"].astype(int).to_numpy()\n",
    "y_test  = test_df[\"label\"].astype(int).to_numpy()\n",
    "\n",
    "# Progress / troubleshooting printouts\n",
    "def describe_sparse(name, X):\n",
    "    nnz = X.nnz if sparse.issparse(X) else np.count_nonzero(X)\n",
    "    total = X.shape[0] * X.shape[1]\n",
    "    density = nnz / total if total else 0.0\n",
    "    print(f\"{name}: shape={X.shape}, nnz={nnz:,}, density={density:.6f}\")\n",
    "\n",
    "describe_sparse(\"X_train\", X_train_sparse)\n",
    "describe_sparse(\"X_val  \", X_val_sparse)\n",
    "describe_sparse(\"X_test \", X_test_sparse)\n",
    "print(\"Targets -> y_train:\", y_train.shape, \"y_val:\", y_val.shape, \"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42cdcced-e98e-49de-bb86-72e703b775eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutations of hyperparameters:\n",
      "\n",
      "n_estimators=200, max_depth=None, min_samples_leaf=1\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.963     0.953     0.958      1800\n",
      "           1      0.953     0.964     0.959      1800\n",
      "\n",
      "    accuracy                          0.958      3600\n",
      "   macro avg      0.958     0.958     0.958      3600\n",
      "weighted avg      0.958     0.958     0.958      3600\n",
      "\n",
      "ROC-AUC: 0.983980864197531\n",
      "PR-AUC : 0.9722960849284576\n",
      "n_estimators=200, max_depth=None, min_samples_leaf=2\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.973     0.951     0.962      1800\n",
      "           1      0.952     0.974     0.963      1800\n",
      "\n",
      "    accuracy                          0.962      3600\n",
      "   macro avg      0.962     0.962     0.962      3600\n",
      "weighted avg      0.962     0.962     0.962      3600\n",
      "\n",
      "ROC-AUC: 0.9880751543209876\n",
      "PR-AUC : 0.9784087021791772\n",
      "n_estimators=200, max_depth=None, min_samples_leaf=5\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.980     0.948     0.964      1800\n",
      "           1      0.950     0.981     0.965      1800\n",
      "\n",
      "    accuracy                          0.964      3600\n",
      "   macro avg      0.965     0.964     0.964      3600\n",
      "weighted avg      0.965     0.964     0.964      3600\n",
      "\n",
      "ROC-AUC: 0.9930893518518519\n",
      "PR-AUC : 0.9914745967191927\n",
      "n_estimators=200, max_depth=10, min_samples_leaf=1\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.947     0.965      1800\n",
      "           1      0.949     0.984     0.966      1800\n",
      "\n",
      "    accuracy                          0.965      3600\n",
      "   macro avg      0.966     0.965     0.965      3600\n",
      "weighted avg      0.966     0.965     0.965      3600\n",
      "\n",
      "ROC-AUC: 0.9941888888888889\n",
      "PR-AUC : 0.9925421666748306\n",
      "n_estimators=200, max_depth=10, min_samples_leaf=2\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.947     0.965      1800\n",
      "           1      0.949     0.984     0.966      1800\n",
      "\n",
      "    accuracy                          0.966      3600\n",
      "   macro avg      0.966     0.966     0.966      3600\n",
      "weighted avg      0.966     0.966     0.966      3600\n",
      "\n",
      "ROC-AUC: 0.9940233024691357\n",
      "PR-AUC : 0.9925666420063093\n",
      "n_estimators=200, max_depth=10, min_samples_leaf=5\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.946     0.964      1800\n",
      "           1      0.948     0.984     0.966      1800\n",
      "\n",
      "    accuracy                          0.965      3600\n",
      "   macro avg      0.966     0.965     0.965      3600\n",
      "weighted avg      0.966     0.965     0.965      3600\n",
      "\n",
      "ROC-AUC: 0.9945182098765433\n",
      "PR-AUC : 0.9934409660559861\n",
      "n_estimators=200, max_depth=20, min_samples_leaf=1\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.971     0.952     0.961      1800\n",
      "           1      0.953     0.971     0.962      1800\n",
      "\n",
      "    accuracy                          0.962      3600\n",
      "   macro avg      0.962     0.962     0.962      3600\n",
      "weighted avg      0.962     0.962     0.962      3600\n",
      "\n",
      "ROC-AUC: 0.9897148148148149\n",
      "PR-AUC : 0.9835816636968611\n",
      "n_estimators=200, max_depth=20, min_samples_leaf=2\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.973     0.952     0.962      1800\n",
      "           1      0.953     0.973     0.963      1800\n",
      "\n",
      "    accuracy                          0.963      3600\n",
      "   macro avg      0.963     0.963     0.962      3600\n",
      "weighted avg      0.963     0.963     0.962      3600\n",
      "\n",
      "ROC-AUC: 0.9911287037037038\n",
      "PR-AUC : 0.985793034227562\n",
      "n_estimators=200, max_depth=20, min_samples_leaf=5\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.947     0.964      1800\n",
      "           1      0.948     0.982     0.965      1800\n",
      "\n",
      "    accuracy                          0.964      3600\n",
      "   macro avg      0.965     0.964     0.964      3600\n",
      "weighted avg      0.965     0.964     0.964      3600\n",
      "\n",
      "ROC-AUC: 0.9936749999999999\n",
      "PR-AUC : 0.9925397997392591\n",
      "n_estimators=400, max_depth=None, min_samples_leaf=1\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.964     0.953     0.958      1800\n",
      "           1      0.953     0.964     0.959      1800\n",
      "\n",
      "    accuracy                          0.959      3600\n",
      "   macro avg      0.959     0.959     0.959      3600\n",
      "weighted avg      0.959     0.959     0.959      3600\n",
      "\n",
      "ROC-AUC: 0.9824577160493827\n",
      "PR-AUC : 0.9696568115356885\n",
      "n_estimators=400, max_depth=None, min_samples_leaf=2\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.973     0.948     0.960      1800\n",
      "           1      0.950     0.973     0.961      1800\n",
      "\n",
      "    accuracy                          0.961      3600\n",
      "   macro avg      0.961     0.961     0.961      3600\n",
      "weighted avg      0.961     0.961     0.961      3600\n",
      "\n",
      "ROC-AUC: 0.9899097222222222\n",
      "PR-AUC : 0.9850840052452183\n",
      "n_estimators=400, max_depth=None, min_samples_leaf=5\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.980     0.949     0.965      1800\n",
      "           1      0.951     0.981     0.966      1800\n",
      "\n",
      "    accuracy                          0.965      3600\n",
      "   macro avg      0.966     0.965     0.965      3600\n",
      "weighted avg      0.966     0.965     0.965      3600\n",
      "\n",
      "ROC-AUC: 0.9933572530864198\n",
      "PR-AUC : 0.9902850700742113\n",
      "n_estimators=400, max_depth=10, min_samples_leaf=1\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.947     0.965      1800\n",
      "           1      0.949     0.984     0.966      1800\n",
      "\n",
      "    accuracy                          0.966      3600\n",
      "   macro avg      0.966     0.966     0.966      3600\n",
      "weighted avg      0.966     0.966     0.966      3600\n",
      "\n",
      "ROC-AUC: 0.9941847222222223\n",
      "PR-AUC : 0.9924525859885035\n",
      "n_estimators=400, max_depth=10, min_samples_leaf=2\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.947     0.965      1800\n",
      "           1      0.949     0.985     0.967      1800\n",
      "\n",
      "    accuracy                          0.966      3600\n",
      "   macro avg      0.967     0.966     0.966      3600\n",
      "weighted avg      0.967     0.966     0.966      3600\n",
      "\n",
      "ROC-AUC: 0.994088425925926\n",
      "PR-AUC : 0.9925942991314348\n",
      "n_estimators=400, max_depth=10, min_samples_leaf=5\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.948     0.965      1800\n",
      "           1      0.950     0.983     0.966      1800\n",
      "\n",
      "    accuracy                          0.966      3600\n",
      "   macro avg      0.966     0.966     0.966      3600\n",
      "weighted avg      0.966     0.966     0.966      3600\n",
      "\n",
      "ROC-AUC: 0.9944427469135801\n",
      "PR-AUC : 0.993357517019337\n",
      "n_estimators=400, max_depth=20, min_samples_leaf=1\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.968     0.952     0.960      1800\n",
      "           1      0.952     0.969     0.961      1800\n",
      "\n",
      "    accuracy                          0.960      3600\n",
      "   macro avg      0.960     0.960     0.960      3600\n",
      "weighted avg      0.960     0.960     0.960      3600\n",
      "\n",
      "ROC-AUC: 0.9893998456790124\n",
      "PR-AUC : 0.983836367768432\n",
      "n_estimators=400, max_depth=20, min_samples_leaf=2\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.974     0.948     0.961      1800\n",
      "           1      0.949     0.974     0.962      1800\n",
      "\n",
      "    accuracy                          0.961      3600\n",
      "   macro avg      0.961     0.961     0.961      3600\n",
      "weighted avg      0.961     0.961     0.961      3600\n",
      "\n",
      "ROC-AUC: 0.9907635802469136\n",
      "PR-AUC : 0.9873522213238758\n",
      "n_estimators=400, max_depth=20, min_samples_leaf=5\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.948     0.964      1800\n",
      "           1      0.950     0.982     0.966      1800\n",
      "\n",
      "    accuracy                          0.965      3600\n",
      "   macro avg      0.966     0.965     0.965      3600\n",
      "weighted avg      0.966     0.965     0.965      3600\n",
      "\n",
      "ROC-AUC: 0.9934103395061729\n",
      "PR-AUC : 0.9918199949959055\n",
      "n_estimators=600, max_depth=None, min_samples_leaf=1\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.964     0.953     0.958      1800\n",
      "           1      0.953     0.964     0.959      1800\n",
      "\n",
      "    accuracy                          0.959      3600\n",
      "   macro avg      0.959     0.959     0.959      3600\n",
      "weighted avg      0.959     0.959     0.959      3600\n",
      "\n",
      "ROC-AUC: 0.9829695987654321\n",
      "PR-AUC : 0.9719629660049864\n",
      "n_estimators=600, max_depth=None, min_samples_leaf=2\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.974     0.948     0.961      1800\n",
      "           1      0.950     0.974     0.962      1800\n",
      "\n",
      "    accuracy                          0.961      3600\n",
      "   macro avg      0.962     0.961     0.961      3600\n",
      "weighted avg      0.962     0.961     0.961      3600\n",
      "\n",
      "ROC-AUC: 0.9887720679012346\n",
      "PR-AUC : 0.9820489453498278\n",
      "n_estimators=600, max_depth=None, min_samples_leaf=5\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.948     0.964      1800\n",
      "           1      0.949     0.982     0.965      1800\n",
      "\n",
      "    accuracy                          0.965      3600\n",
      "   macro avg      0.965     0.965     0.965      3600\n",
      "weighted avg      0.965     0.965     0.965      3600\n",
      "\n",
      "ROC-AUC: 0.9933345679012345\n",
      "PR-AUC : 0.9918653031165691\n",
      "n_estimators=600, max_depth=10, min_samples_leaf=1\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.947     0.965      1800\n",
      "           1      0.949     0.984     0.966      1800\n",
      "\n",
      "    accuracy                          0.966      3600\n",
      "   macro avg      0.966     0.966     0.966      3600\n",
      "weighted avg      0.966     0.966     0.966      3600\n",
      "\n",
      "ROC-AUC: 0.994170524691358\n",
      "PR-AUC : 0.9923682219118604\n",
      "n_estimators=600, max_depth=10, min_samples_leaf=2\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.947     0.965      1800\n",
      "           1      0.949     0.985     0.967      1800\n",
      "\n",
      "    accuracy                          0.966      3600\n",
      "   macro avg      0.967     0.966     0.966      3600\n",
      "weighted avg      0.967     0.966     0.966      3600\n",
      "\n",
      "ROC-AUC: 0.9941310185185186\n",
      "PR-AUC : 0.9926900548581559\n",
      "n_estimators=600, max_depth=10, min_samples_leaf=5\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.947     0.965      1800\n",
      "           1      0.949     0.983     0.966      1800\n",
      "\n",
      "    accuracy                          0.965      3600\n",
      "   macro avg      0.966     0.965     0.965      3600\n",
      "weighted avg      0.966     0.965     0.965      3600\n",
      "\n",
      "ROC-AUC: 0.99443487654321\n",
      "PR-AUC : 0.9933471021570496\n",
      "n_estimators=600, max_depth=20, min_samples_leaf=1\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.968     0.953     0.960      1800\n",
      "           1      0.954     0.968     0.961      1800\n",
      "\n",
      "    accuracy                          0.961      3600\n",
      "   macro avg      0.961     0.961     0.961      3600\n",
      "weighted avg      0.961     0.961     0.961      3600\n",
      "\n",
      "ROC-AUC: 0.9895274691358024\n",
      "PR-AUC : 0.9842052080493541\n",
      "n_estimators=600, max_depth=20, min_samples_leaf=2\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.973     0.949     0.961      1800\n",
      "           1      0.950     0.974     0.962      1800\n",
      "\n",
      "    accuracy                          0.961      3600\n",
      "   macro avg      0.962     0.961     0.961      3600\n",
      "weighted avg      0.962     0.961     0.961      3600\n",
      "\n",
      "ROC-AUC: 0.9911112654320987\n",
      "PR-AUC : 0.9859680357719623\n",
      "n_estimators=600, max_depth=20, min_samples_leaf=5\n",
      "\n",
      "=== Test (after human update) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.948     0.964      1800\n",
      "           1      0.950     0.982     0.966      1800\n",
      "\n",
      "    accuracy                          0.965      3600\n",
      "   macro avg      0.966     0.965     0.965      3600\n",
      "weighted avg      0.966     0.965     0.965      3600\n",
      "\n",
      "ROC-AUC: 0.9933887345679013\n",
      "PR-AUC : 0.9920226202398311\n",
      "\n",
      "Grid search completed.\n"
     ]
    }
   ],
   "source": [
    "n_estimators_list   = [200, 400, 600]\n",
    "max_depth_list      = [None, 10, 20]\n",
    "min_samples_leaf_list = [1, 2, 5]\n",
    "MAX_ERROR_FRACTION = 0.5  # e.g., at most XX % of the batch are errors\n",
    "\n",
    "def build_class_batch(err_idx, corr_pool, target_n):\n",
    "    \"\"\"Always include as many errors as possible up to target_n,\n",
    "    then fill with correct examples if needed.\"\"\"\n",
    "    err_idx = np.asarray(err_idx)\n",
    "    corr_pool = np.asarray(corr_pool)\n",
    "    \n",
    "    # desired number of errors, but not more than we actually have\n",
    "    max_err_allowed = int(target_n * MAX_ERROR_FRACTION)\n",
    "    n_err = min(len(err_idx), max_err_allowed)\n",
    "    n_corr = target_n - n_err\n",
    "    \n",
    "    chosen_err = rng.choice(err_idx, size=n_err, replace=False) if n_err > 0 else np.array([], dtype=int)\n",
    "    chosen_corr = rng.choice(corr_pool, size=n_corr, replace=False) if n_corr > 0 else np.array([], dtype=int)\n",
    "    \n",
    "    return np.concatenate([chosen_err, chosen_corr])\n",
    "\n",
    "# Permutation of hyperparameters including HITL logic\n",
    "print(\"Permutations of hyperparameters:\\n\")\n",
    "\n",
    "for n_est, depth, leaf in product(n_estimators_list, max_depth_list, min_samples_leaf_list):\n",
    "    print(f\"n_estimators={n_est}, max_depth={depth}, min_samples_leaf={leaf}\")\n",
    "    \n",
    "    clf = RandomForestClassifier(\n",
    "    n_estimators=n_est,      # try 200–500\n",
    "    max_depth=depth,       # or e.g. 10 if you want to regularize\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=leaf,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train_sparse, y_train)\n",
    "\n",
    "    # ---- TRAIN METRICS ----\n",
    "    train_probs = clf.predict_proba(X_train_sparse)[:, 1]\n",
    "    train_preds = (train_probs >= 0.5).astype(int)\n",
    "    \n",
    "\n",
    "    # ---- VALIDATION METRICS ----\n",
    "    val_probs  = clf.predict_proba(X_val_sparse)[:, 1]\n",
    "    val_preds  = (val_probs >= 0.5).astype(int)\n",
    "    \n",
    "    \n",
    "    # ---- TEST METRICS ---- (baseline generalization)  \n",
    "    test_probs = clf.predict_proba(X_test_sparse)[:, 1]\n",
    "    test_preds = (test_probs >= 0.5).astype(int)\n",
    "\n",
    "    # Build indices for errors and correct predictions\n",
    "    y_val_np = np.asarray(y_val)\n",
    "    val_errors_mask = (val_preds != y_val_np)\n",
    "    \n",
    "    # Indices of errors per class\n",
    "    err_0_idx = np.where(val_errors_mask & (y_val_np == 0))[0]\n",
    "    err_1_idx = np.where(val_errors_mask & (y_val_np == 1))[0]\n",
    "    \n",
    "    # Indices of correctly classified examples per class\n",
    "    corr_0_pool = np.where((~val_errors_mask) & (y_val_np == 0))[0]\n",
    "    corr_1_pool = np.where((~val_errors_mask) & (y_val_np == 1))[0]\n",
    "    \n",
    "    rng = np.random.default_rng(SEED)\n",
    "    \n",
    "    # Choose a target number per class.\n",
    "    # Option A: use the smaller available total to avoid running out.\n",
    "    max_per_class_0 = len(err_0_idx) + len(corr_0_pool)\n",
    "    max_per_class_1 = len(err_1_idx) + len(corr_1_pool)\n",
    "    target_per_class = min(max_per_class_0, max_per_class_1, 200)  # cap at 200 per class, for example \n",
    "    \n",
    "    human_idx_0 = build_class_batch(err_0_idx, corr_0_pool, target_per_class)\n",
    "    human_idx_1 = build_class_batch(err_1_idx, corr_1_pool, target_per_class)\n",
    "    \n",
    "    # Final balanced human batch indices\n",
    "    human_idx = np.concatenate([human_idx_0, human_idx_1])\n",
    "    rng.shuffle(human_idx)\n",
    "    \n",
    "    X_human = X_val_sparse[human_idx]\n",
    "    y_human = y_val_np[human_idx]\n",
    "    \n",
    "    err_0_contrib = np.intersect1d(human_idx_0, err_0_idx).size\n",
    "    corr_0_contrib = human_idx_0.size - err_0_contrib\n",
    "    \n",
    "    err_1_contrib = np.intersect1d(human_idx_1, err_1_idx).size\n",
    "    corr_1_contrib = human_idx_1.size - err_1_contrib\n",
    "\n",
    "    # Combine original train data with human batch\n",
    "    X_train_ext = sparse.vstack([X_train_sparse, X_human])\n",
    "    y_train_ext = np.concatenate([y_train, y_human])\n",
    "    \n",
    "    # Retrain selected model on extended data\n",
    "    clf.fit(X_train_ext, y_train_ext)\n",
    "\n",
    "    # Re-score test (unseen) to measure true generalization change\n",
    "    test_probs2 = clf.predict_proba(X_test_sparse)[:, 1]\n",
    "    test_preds2 = (test_probs2 >= 0.5).astype(int)\n",
    "    \n",
    "    print(\"\\n=== Test (after human update) ===\")\n",
    "    print(classification_report(y_test, test_preds2, digits=3))\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_test, test_probs2))\n",
    "    print(\"PR-AUC :\", average_precision_score(y_test, test_probs2))\n",
    "\n",
    "\n",
    "print(\"\\nGrid search completed.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea7059-a064-48cf-a43e-da3cf7a25444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343151f-3dd1-4c5c-a0e4-fefd5b49fcf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73df0fbe-9bb4-4683-b15c-08a698ab5a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
